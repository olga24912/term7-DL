{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ImdbMovieReviews:\n",
    "    \"\"\"\n",
    "    The movie review dataset is offered by Stanford Universityâ€™s AI department:\n",
    "    http://ai.stanford.edu/~amaas/data/sentiment/. It comes as a compressed  tar  archive where\n",
    "    positive and negative reviews can be found as text files in two according folders. We apply\n",
    "    the same pre-processing to the text as in the last section: Extracting plain words using a\n",
    "    regular expression and converting to lower case.\n",
    "    \"\"\"\n",
    "    DEFAULT_URL = \\\n",
    "        'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    TOKEN_REGEX = re.compile(r'[A-Za-z]+|[!?.:,()]')\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cache_dir = './imdb'\n",
    "        self._url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "        \n",
    "        if not os.path.isfile(self._cache_dir):\n",
    "            urllib.request.urlretrieve(self._url, self._cache_dir)\n",
    "        self.filepath = self._cache_dir\n",
    "\n",
    "    def __iter__(self):\n",
    "        with tarfile.open(self.filepath) as archive:\n",
    "            items = archive.getnames()\n",
    "            for filename in archive.getnames():\n",
    "                if filename.startswith('aclImdb/test/pos/'):\n",
    "                    yield self._read(archive, filename), True\n",
    "                elif filename.startswith('aclImdb/test/neg/'):\n",
    "                    yield self._read(archive, filename), False\n",
    "                    \n",
    "    def _read(self, archive, filename):\n",
    "        with archive.extractfile(filename) as file_:\n",
    "            data = file_.read().decode('utf-8')\n",
    "            data = type(self).TOKEN_REGEX.findall(data)\n",
    "            data = [x.lower() for x in data]\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Spacy is my favourite nlp framework, which havu builtin word embeddings trains on wikipesia\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "class Embedding:\n",
    "    \n",
    "    def __init__(self, length):\n",
    "#          spaCy makes using word vectors very easy. \n",
    "#             The Lexeme , Token , Span  and Doc  classes all have a .vector property,\n",
    "#             which is a 1-dimensional numpy array of 32-bit floats:\n",
    "        self.parser = spacy.load('en_vectors_web_lg')\n",
    "        self._length = length\n",
    "        self.dimensions = 300\n",
    "        \n",
    "    def __call__(self, sequence):\n",
    "        data = np.zeros((self._length, self.dimensions))\n",
    "        # you can access known words from the parser's vocabulary\n",
    "        embedded = [self.parser.vocab[w].vector for w in sequence]\n",
    "        data[:len(sequence)] = embedded\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lazy import lazy\n",
    "\n",
    "class SequenceClassificationModel:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self._create_placeholders()\n",
    "        self.prediction\n",
    "        self.cost\n",
    "        self.error\n",
    "        self.optimize\n",
    "        self.global_step = 0\n",
    "        self._create_summaries()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _create_placeholders(self):\n",
    "        with tf.name_scope(\"data\"):\n",
    "            self.data = tf.placeholder(tf.float32, [None, self.params.seq_length, self.params.embed_length])\n",
    "            self.target = tf.placeholder(tf.float32, [None, 2])\n",
    "  \n",
    "    def _create_summaries(self):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            tf.summary.scalar('loss', self.cost)\n",
    "            tf.summary.scalar('erroe', self.error)\n",
    "            self.summary = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "    @lazy\n",
    "    def length(self):\n",
    "        with tf.name_scope(\"seq_length\"):\n",
    "            used = tf.sign(tf.reduce_max(tf.abs(self.data), reduction_indices=2))\n",
    "            length = tf.reduce_sum(used, reduction_indices=1)\n",
    "            length = tf.cast(length, tf.int32)\n",
    "        return length\n",
    "    \n",
    "    @lazy\n",
    "    def prediction(self):\n",
    "        with tf.name_scope(\"recurrent_layer\"):\n",
    "            output, _ = tf.nn.dynamic_rnn(\n",
    "                self.params.rnn_cell(self.params.rnn_hidden),\n",
    "                self.data,\n",
    "                dtype=tf.float32,\n",
    "                sequence_length=self.length\n",
    "            )\n",
    "        last = self._last_relevant(output, self.length)\n",
    "\n",
    "        with tf.name_scope(\"softmax_layer\"):\n",
    "            num_classes = int(self.target.get_shape()[1])\n",
    "            weight = tf.Variable(tf.truncated_normal(\n",
    "                [self.params.rnn_hidden, num_classes], stddev=0.01))\n",
    "            bias = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "            prediction = tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "        return prediction\n",
    "    \n",
    "    @lazy\n",
    "    def cost(self):\n",
    "        cross_entropy = -tf.reduce_sum(self.target * tf.log(self.prediction))\n",
    "        return cross_entropy\n",
    "    \n",
    "    @lazy\n",
    "    def error(self):\n",
    "        self.mistakes = tf.not_equal(\n",
    "            tf.argmax(self.target, 1), tf.argmax(self.prediction, 1))\n",
    "        return tf.reduce_mean(tf.cast(self.mistakes, tf.float32))\n",
    "    \n",
    "    @lazy\n",
    "    def optimize(self):\n",
    "        with tf.name_scope(\"optimization\"):\n",
    "            gradient = self.params.optimizer.compute_gradients(self.cost)\n",
    "            if self.params.gradient_clipping:\n",
    "                limit = self.params.gradient_clipping\n",
    "                gradient = [\n",
    "                    (tf.clip_by_value(g, -limit, limit), v)\n",
    "                    if g is not None else (None, v)\n",
    "                    for g, v in gradient]\n",
    "            optimize = self.params.optimizer.apply_gradients(gradient)\n",
    "        return optimize\n",
    "    \n",
    "    @staticmethod\n",
    "    def _last_relevant(output, length):\n",
    "        with tf.name_scope(\"last_relevant\"):\n",
    "            # As of now, TensorFlow only supports indexing along the first dimension, using\n",
    "            # tf.gather() . We thus flatten the first two dimensions of the output activations from their\n",
    "            # shape of  sequences x time_steps x word_vectors  and construct an index into this resulting tensor.\n",
    "            batch_size = tf.shape(output)[0]\n",
    "            max_length = int(output.get_shape()[1])\n",
    "            output_size = int(output.get_shape()[2])\n",
    "\n",
    "            # The index takes into account the start indices for each sequence in the flat tensor and adds\n",
    "            # the sequence length to it. Actually, we only add  length - 1  so that we select the last valid\n",
    "            # time step.\n",
    "            index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "            flat = tf.reshape(output, [-1, output_size])\n",
    "            relevant = tf.gather(flat, index)\n",
    "        return relevant\n",
    "    \n",
    "    def train(self, batches, save_prefix, save_every=10):\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir('./saved/'):\n",
    "            saver.restore(self.sess, tf.train.latest_checkpoint('./saved/'))\n",
    "        else:\n",
    "            os.makedirs('saved')\n",
    "        summary_writer = tf.summary.FileWriter('graphs/run{}'.format(self.global_step), self.sess.graph)\n",
    "        self.global_step += 1\n",
    "        for index, batch in enumerate(batches):\n",
    "            feed = {model.data: batch[0], model.target: batch[1]}\n",
    "            error, _, summary_str = self.sess.run([model.error, model.optimize, model.summary], feed)\n",
    "            print('{}: {:3.1f}%'.format(index + 1, 100 * error))\n",
    "            if index % save_every == 0:\n",
    "                summary_writer.add_summary(summary_str, index)\n",
    "                summary_writer.flush()\n",
    "            if index % save_every == 0:\n",
    "                save_path = os.path.join('checkpoints', save_prefix)\n",
    "                print('saving...', save_path)\n",
    "                saver.save(self.sess, save_path, global_step=index)\n",
    "        saver.save(self.sess, os.path.join('checkpoints', save_prefix + '_final'))\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        feed = {model.data: data, }\n",
    "        prediction = self.sess.run([model.prediction], feed)        \n",
    "        return prediction\n",
    "        \n",
    "    def close(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_batched(iterator, length, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        data = np.zeros((batch_size, length, embedding.dimensions))\n",
    "        target = np.zeros((batch_size, 2))\n",
    "        for index in range(batch_size):\n",
    "            text, label = next(iterator)\n",
    "            data[index] = embedding(text)\n",
    "            target[index] = [1, 0] if label else [0, 1]\n",
    "        yield data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews = list(ImdbMovieReviews())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = max(len(x[0]) for x in reviews)\n",
    "embedding = Embedding(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrdict import AttrDict\n",
    "import tensorflow as tf\n",
    "\n",
    "params = AttrDict(\n",
    "    rnn_cell=tf.contrib.rnn.GRUCell,\n",
    "    rnn_hidden=300,\n",
    "    optimizer=tf.train.RMSPropOptimizer(0.002),\n",
    "    batch_size=20,\n",
    "    gradient_clipping=100,\n",
    "    seq_length=length,\n",
    "    embed_length=embedding.dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = preprocess_batched(reviews, length, embedding, params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olga/soft/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = SequenceClassificationModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(batches, save_prefix='simple-rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from no_att_checkpoints/simple-rnn-1240\n",
      "INFO:tensorflow:Restoring parameters from no_att_checkpoints/simple-rnn-1240\n",
      "0 accuracy= 0.8\n",
      "1 accuracy= 0.75\n",
      "2 accuracy= 0.7833333333333333\n",
      "3 accuracy= 0.825\n",
      "4 accuracy= 0.82\n",
      "5 accuracy= 0.85\n",
      "6 accuracy= 0.8642857142857143\n",
      "7 accuracy= 0.875\n",
      "8 accuracy= 0.8833333333333333\n",
      "9 accuracy= 0.885\n",
      "10 accuracy= 0.8863636363636364\n",
      "11 accuracy= 0.8875\n",
      "12 accuracy= 0.8884615384615384\n",
      "13 accuracy= 0.8785714285714286\n",
      "14 accuracy= 0.8766666666666667\n",
      "15 accuracy= 0.878125\n",
      "16 accuracy= 0.8764705882352941\n",
      "17 accuracy= 0.8722222222222222\n",
      "18 accuracy= 0.8710526315789474\n",
      "19 accuracy= 0.8675\n",
      "20 accuracy= 0.8714285714285714\n",
      "21 accuracy= 0.8681818181818182\n",
      "22 accuracy= 0.8717391304347826\n",
      "23 accuracy= 0.86875\n",
      "24 accuracy= 0.872\n",
      "25 accuracy= 0.875\n",
      "26 accuracy= 0.8777777777777778\n",
      "27 accuracy= 0.8785714285714286\n",
      "28 accuracy= 0.8758620689655172\n",
      "29 accuracy= 0.875\n",
      "30 accuracy= 0.8741935483870967\n",
      "31 accuracy= 0.875\n",
      "32 accuracy= 0.8742424242424243\n",
      "33 accuracy= 0.8735294117647059\n",
      "34 accuracy= 0.8728571428571429\n",
      "35 accuracy= 0.8736111111111111\n",
      "36 accuracy= 0.8743243243243243\n",
      "37 accuracy= 0.875\n",
      "38 accuracy= 0.8756410256410256\n",
      "39 accuracy= 0.87625\n",
      "40 accuracy= 0.8768292682926829\n",
      "41 accuracy= 0.8761904761904762\n",
      "42 accuracy= 0.8732558139534884\n",
      "43 accuracy= 0.875\n",
      "44 accuracy= 0.8733333333333333\n",
      "45 accuracy= 0.8760869565217392\n",
      "46 accuracy= 0.874468085106383\n",
      "47 accuracy= 0.8770833333333333\n",
      "48 accuracy= 0.8785714285714286\n",
      "49 accuracy= 0.88\n",
      "50 accuracy= 0.8794117647058823\n",
      "51 accuracy= 0.8807692307692307\n",
      "52 accuracy= 0.8830188679245283\n",
      "53 accuracy= 0.8842592592592593\n",
      "54 accuracy= 0.8854545454545455\n",
      "55 accuracy= 0.8830357142857143\n",
      "56 accuracy= 0.8833333333333333\n",
      "57 accuracy= 0.8844827586206897\n",
      "58 accuracy= 0.8822033898305085\n",
      "59 accuracy= 0.8816666666666667\n",
      "60 accuracy= 0.8819672131147541\n",
      "61 accuracy= 0.8806451612903226\n",
      "62 accuracy= 0.8785714285714286\n",
      "63 accuracy= 0.8796875\n",
      "64 accuracy= 0.88\n",
      "65 accuracy= 0.8810606060606061\n",
      "66 accuracy= 0.8798507462686567\n",
      "67 accuracy= 0.8808823529411764\n",
      "68 accuracy= 0.8826086956521739\n",
      "69 accuracy= 0.8821428571428571\n",
      "70 accuracy= 0.8823943661971831\n",
      "71 accuracy= 0.8826388888888889\n",
      "72 accuracy= 0.8828767123287671\n",
      "73 accuracy= 0.8824324324324324\n",
      "74 accuracy= 0.882\n",
      "75 accuracy= 0.8809210526315789\n",
      "76 accuracy= 0.8798701298701299\n",
      "77 accuracy= 0.8801282051282051\n",
      "78 accuracy= 0.8803797468354431\n",
      "79 accuracy= 0.88\n",
      "80 accuracy= 0.8814814814814815\n",
      "81 accuracy= 0.8817073170731707\n",
      "82 accuracy= 0.8813253012048192\n",
      "83 accuracy= 0.8803571428571428\n",
      "84 accuracy= 0.8805882352941177\n",
      "85 accuracy= 0.8819767441860465\n",
      "86 accuracy= 0.8827586206896552\n",
      "87 accuracy= 0.8829545454545454\n",
      "88 accuracy= 0.8837078651685393\n",
      "89 accuracy= 0.885\n",
      "90 accuracy= 0.8857142857142857\n",
      "91 accuracy= 0.8853260869565217\n",
      "92 accuracy= 0.8849462365591397\n",
      "93 accuracy= 0.8856382978723404\n",
      "94 accuracy= 0.8857894736842106\n",
      "95 accuracy= 0.8864583333333333\n",
      "96 accuracy= 0.8876288659793814\n",
      "97 accuracy= 0.8877551020408163\n",
      "98 accuracy= 0.8888888888888888\n",
      "99 accuracy= 0.888\n",
      "100 accuracy= 0.8891089108910891\n",
      "101 accuracy= 0.8887254901960784\n",
      "102 accuracy= 0.8898058252427185\n",
      "103 accuracy= 0.8899038461538461\n",
      "104 accuracy= 0.8904761904761904\n",
      "105 accuracy= 0.8900943396226415\n",
      "106 accuracy= 0.8911214953271028\n",
      "107 accuracy= 0.8907407407407407\n",
      "108 accuracy= 0.8908256880733945\n",
      "109 accuracy= 0.8904545454545455\n",
      "110 accuracy= 0.8891891891891892\n",
      "111 accuracy= 0.8892857142857142\n",
      "112 accuracy= 0.8898230088495576\n",
      "113 accuracy= 0.8903508771929824\n",
      "114 accuracy= 0.8904347826086957\n",
      "115 accuracy= 0.8900862068965517\n",
      "116 accuracy= 0.8897435897435897\n",
      "117 accuracy= 0.8902542372881356\n",
      "118 accuracy= 0.8903361344537815\n",
      "119 accuracy= 0.89\n",
      "120 accuracy= 0.8896694214876033\n",
      "121 accuracy= 0.8905737704918033\n",
      "122 accuracy= 0.8910569105691057\n",
      "123 accuracy= 0.8903225806451613\n",
      "124 accuracy= 0.89\n",
      "125 accuracy= 0.890079365079365\n",
      "126 accuracy= 0.889763779527559\n",
      "127 accuracy= 0.889453125\n",
      "128 accuracy= 0.8887596899224807\n",
      "129 accuracy= 0.8892307692307693\n",
      "130 accuracy= 0.8885496183206106\n",
      "131 accuracy= 0.8878787878787879\n",
      "132 accuracy= 0.8883458646616541\n",
      "133 accuracy= 0.8884328358208955\n",
      "134 accuracy= 0.8881481481481481\n",
      "135 accuracy= 0.888235294117647\n",
      "136 accuracy= 0.8875912408759125\n",
      "137 accuracy= 0.8869565217391304\n",
      "138 accuracy= 0.8870503597122302\n",
      "139 accuracy= 0.8875\n",
      "140 accuracy= 0.8875886524822695\n",
      "141 accuracy= 0.8880281690140845\n",
      "142 accuracy= 0.8874125874125874\n",
      "143 accuracy= 0.8868055555555555\n",
      "144 accuracy= 0.8875862068965518\n",
      "145 accuracy= 0.8876712328767123\n",
      "146 accuracy= 0.8870748299319728\n",
      "147 accuracy= 0.8868243243243243\n",
      "148 accuracy= 0.8869127516778523\n",
      "149 accuracy= 0.8873333333333333\n",
      "150 accuracy= 0.8870860927152318\n",
      "151 accuracy= 0.8875\n",
      "152 accuracy= 0.888235294117647\n",
      "153 accuracy= 0.8886363636363637\n",
      "154 accuracy= 0.8880645161290323\n",
      "155 accuracy= 0.8881410256410256\n",
      "156 accuracy= 0.8888535031847133\n",
      "157 accuracy= 0.8886075949367088\n",
      "158 accuracy= 0.8880503144654088\n",
      "159 accuracy= 0.8878125\n",
      "160 accuracy= 0.8875776397515528\n",
      "161 accuracy= 0.8873456790123457\n",
      "162 accuracy= 0.8871165644171779\n",
      "163 accuracy= 0.8875\n",
      "164 accuracy= 0.8878787878787879\n",
      "165 accuracy= 0.8873493975903615\n",
      "166 accuracy= 0.887125748502994\n",
      "167 accuracy= 0.887797619047619\n",
      "168 accuracy= 0.8878698224852071\n",
      "169 accuracy= 0.8876470588235295\n",
      "170 accuracy= 0.887719298245614\n",
      "171 accuracy= 0.8880813953488372\n",
      "172 accuracy= 0.888150289017341\n",
      "173 accuracy= 0.8885057471264368\n",
      "174 accuracy= 0.8888571428571429\n",
      "175 accuracy= 0.8883522727272727\n",
      "176 accuracy= 0.8887005649717514\n",
      "177 accuracy= 0.8887640449438202\n",
      "178 accuracy= 0.8891061452513966\n",
      "179 accuracy= 0.8886111111111111\n",
      "180 accuracy= 0.8892265193370166\n",
      "181 accuracy= 0.8892857142857142\n",
      "182 accuracy= 0.8898907103825137\n",
      "183 accuracy= 0.8894021739130434\n",
      "184 accuracy= 0.8894594594594595\n",
      "185 accuracy= 0.8895161290322581\n",
      "186 accuracy= 0.8895721925133689\n",
      "187 accuracy= 0.8888297872340426\n",
      "188 accuracy= 0.888095238095238\n",
      "189 accuracy= 0.8881578947368421\n",
      "190 accuracy= 0.8876963350785341\n",
      "191 accuracy= 0.88828125\n",
      "192 accuracy= 0.888860103626943\n",
      "193 accuracy= 0.8889175257731958\n",
      "194 accuracy= 0.888974358974359\n",
      "195 accuracy= 0.8892857142857142\n",
      "196 accuracy= 0.8895939086294417\n",
      "197 accuracy= 0.8896464646464647\n",
      "198 accuracy= 0.8899497487437186\n",
      "199 accuracy= 0.88925\n",
      "200 accuracy= 0.8895522388059701\n",
      "201 accuracy= 0.8893564356435644\n",
      "202 accuracy= 0.8889162561576355\n",
      "203 accuracy= 0.8892156862745098\n",
      "204 accuracy= 0.8890243902439025\n",
      "205 accuracy= 0.8890776699029126\n",
      "206 accuracy= 0.8891304347826087\n",
      "207 accuracy= 0.8894230769230769\n",
      "208 accuracy= 0.8892344497607656\n",
      "209 accuracy= 0.8890476190476191\n",
      "210 accuracy= 0.8890995260663507\n",
      "211 accuracy= 0.8896226415094339\n",
      "212 accuracy= 0.889906103286385\n",
      "213 accuracy= 0.8894859813084112\n",
      "214 accuracy= 0.8893023255813953\n",
      "215 accuracy= 0.8893518518518518\n",
      "216 accuracy= 0.8894009216589862\n",
      "217 accuracy= 0.8894495412844037\n",
      "218 accuracy= 0.889269406392694\n",
      "219 accuracy= 0.8888636363636364\n",
      "220 accuracy= 0.8886877828054298\n",
      "221 accuracy= 0.8891891891891892\n",
      "222 accuracy= 0.889237668161435\n",
      "223 accuracy= 0.8897321428571429\n",
      "224 accuracy= 0.8897777777777778\n",
      "225 accuracy= 0.8900442477876106\n",
      "226 accuracy= 0.8894273127753304\n",
      "227 accuracy= 0.8888157894736842\n",
      "228 accuracy= 0.8890829694323145\n",
      "229 accuracy= 0.8895652173913043\n",
      "230 accuracy= 0.8893939393939394\n",
      "231 accuracy= 0.8887931034482759\n",
      "232 accuracy= 0.8888412017167382\n",
      "233 accuracy= 0.8888888888888888\n",
      "234 accuracy= 0.8885106382978724\n",
      "235 accuracy= 0.888135593220339\n",
      "236 accuracy= 0.8879746835443038\n",
      "237 accuracy= 0.8878151260504201\n",
      "238 accuracy= 0.8880753138075314\n",
      "239 accuracy= 0.888125\n",
      "240 accuracy= 0.8881742738589211\n",
      "241 accuracy= 0.8884297520661157\n",
      "242 accuracy= 0.8888888888888888\n",
      "243 accuracy= 0.889344262295082\n",
      "244 accuracy= 0.8889795918367347\n",
      "245 accuracy= 0.8892276422764228\n",
      "246 accuracy= 0.8888663967611335\n",
      "247 accuracy= 0.8887096774193548\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a22507fdacb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/olga/soft/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/olga/soft/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/olga/soft/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/olga/soft/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/olga/soft/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "checkpoint_dir = 'no_att_checkpoints'\n",
    "checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if checkpoint:\n",
    "    print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "    saver.restore(model.sess, checkpoint.model_checkpoint_path)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Cannot restore model\")\n",
    "\n",
    "    \n",
    "cnt_rght = 0\n",
    "cnt_wrng = 0\n",
    "\n",
    "for index, batch in enumerate(batches):\n",
    "    feed = {model.data: batch[0]}\n",
    "    prediction = model.sess.run(model.prediction, feed)\n",
    "    for i in range(len(prediction)):\n",
    "        if (prediction[i][0] <= prediction[i][1] and batch[1][i][0] <= batch[1][i][1]):\n",
    "            cnt_rght += 1\n",
    "        elif (prediction[i][0] > prediction[i][1] and batch[1][i][0] > batch[1][i][1]):\n",
    "            cnt_rght += 1\n",
    "        else:\n",
    "            cnt_wrng += 1\n",
    "    \n",
    "    print(index, \"accuracy=\", cnt_rght/(cnt_rght + cnt_wrng))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
